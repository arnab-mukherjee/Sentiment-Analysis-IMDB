{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import files and convert to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Rating\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...      1\n",
       "1  Homelessness (or Houselessness as George Carli...      1\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...      1\n",
       "3  This is easily the most underrated film inn th...      1\n",
       "4  This is not the typical Mel Brooks film. It wa...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpath = \"./aclImdb/train/\"\n",
    "outpath = \"./\"\n",
    "name=\"training data\"\n",
    "\n",
    "text = []\n",
    "rating = []\n",
    "\n",
    "for filename in os.listdir(inpath+\"pos\"):\n",
    "    data = open(inpath+\"pos/\"+filename,'r', encoding = \"ISO-8859-1\").read()\n",
    "    text.append(data)\n",
    "    rating.append(\"1\")\n",
    "\n",
    "for filename in os.listdir(inpath+\"neg\"):\n",
    "    data = open(inpath+\"neg/\"+filename,'r', encoding = \"ISO-8859-1\").read()\n",
    "    text.append(data)\n",
    "    rating.append(\"0\")\n",
    "\n",
    "dataset = list(zip(text,rating))\n",
    "\n",
    "data_train = pd.DataFrame(data=dataset, columns=['Review',\"Rating\"])\n",
    "\n",
    "data_train.to_csv(outpath+name, header=True)\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Rating\n",
       "0  I went and saw this movie last night after bei...      1\n",
       "1  Actor turned director Bill Paxton follows up h...      1\n",
       "2  As a recreational golfer with some knowledge o...      1\n",
       "3  I saw this film in a sneak preview, and it is ...      1\n",
       "4  Bill Paxton has taken the true story of the 19...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpath = \"./aclImdb/test/\"\n",
    "outpath = \"./\"\n",
    "name=\"testing data\"\n",
    "\n",
    "text = []\n",
    "rating = []\n",
    "\n",
    "for filename in os.listdir(inpath+\"pos\"):\n",
    "    data = open(inpath+\"pos/\"+filename,'r', encoding = \"ISO-8859-1\").read()\n",
    "    text.append(data)\n",
    "    rating.append(\"1\")\n",
    "\n",
    "for filename in os.listdir(inpath+\"neg\"):\n",
    "    data = open(inpath+\"neg/\"+filename,'r', encoding = \"ISO-8859-1\").read()\n",
    "    text.append(data)\n",
    "    rating.append(\"0\")\n",
    "\n",
    "dataset = list(zip(text,rating))\n",
    "\n",
    "data_test = pd.DataFrame(data=dataset, columns=['Review',\"Rating\"])\n",
    "\n",
    "data_test.to_csv(outpath+name, header=True)\n",
    "\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove HTML format text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_data):\n",
    "    cleaner = re.compile('<.*?>')\n",
    "    clean_text = re.sub(cleaner, '', raw_data)\n",
    "    return clean_text\n",
    "\n",
    "data_train[\"Review_NoHTML\"] = data_train[\"Review\"].apply(lambda z:cleanhtml(z))\n",
    "data_test[\"Review_NoHTML\"] = data_test[\"Review\"].apply(lambda z:cleanhtml(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    text_nopunc = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunc\n",
    "\n",
    "data_train[\"Review_NoPunc\"] = data_train[\"Review_NoHTML\"].apply(lambda z:remove_punc(z))\n",
    "data_test[\"Review_NoPunc\"] = data_test[\"Review_NoHTML\"].apply(lambda z:remove_punc(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.split(\"\\W+\",text)\n",
    "    return(tokens)\n",
    "\n",
    "data_train[\"Review_tokenized\"] = data_train[\"Review_NoPunc\"].apply(lambda x:tokenize(x.lower()))\n",
    "data_test[\"Review_tokenized\"] = data_test[\"Review_NoPunc\"].apply(lambda x:tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(tokenized_words):\n",
    "    text = [word for word in tokenized_words if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "data_train[\"Review_NoStop\"] = data_train[\"Review_tokenized\"].apply(lambda x:remove_stopwords(x))\n",
    "data_test[\"Review_NoStop\"] = data_test[\"Review_tokenized\"].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return (text)\n",
    "\n",
    "data_train[\"Review_Stemmed\"] = data_train[\"Review_NoStop\"].apply(lambda x:stemming(x))\n",
    "data_test[\"Review_Stemmed\"] = data_test[\"Review_NoStop\"].apply(lambda x:stemming(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "data_train[\"Review_Lemmatized\"] = data_train[\"Review_Stemmed\"].apply(lambda x:lemmatizing(x))\n",
    "data_test[\"Review_Lemmatized\"] = data_test[\"Review_Stemmed\"].apply(lambda x:lemmatizing(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to Array for tfidfVectorizor\n",
    "data_train['Review_Stemmed']=[\" \".join(review) for review in data_train['Review_Stemmed'].values]\n",
    "data_test['Review_Stemmed']=[\" \".join(review) for review in data_test['Review_Stemmed'].values]\n",
    "\n",
    "#Split Training and Testing Data\n",
    "X_train = data_train.loc[:, 'Review_Stemmed']\n",
    "y_train = data_train.loc[:, 'Rating']\n",
    "X_test = data_test.loc[:, 'Review_Stemmed']\n",
    "y_test = data_test.loc[:, 'Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (25001, 113484)\n",
      "Shape:  (25000, 113484)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_idf = vectorizer.fit_transform(X_train)\n",
    "print(\"Shape: \", X_train_idf.shape)\n",
    "\n",
    "X_test_idf = vectorizer.transform(X_test)\n",
    "print(\"Shape: \", X_test_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models: Logistic Regression, Random Forest and Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "          token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None)),\n",
       " ('clf',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "            n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "            tol=0.0001, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "final_pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnab\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\arnab\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:436: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "-----------------------------------\n",
      "fit_time  mean  2.4235368569691977\n",
      "fit_time  std  0.09757571344076234\n",
      "score_time  mean  0.9156997203826904\n",
      "score_time  std  0.05111293198619878\n",
      "test_score  mean  0.8508061992746088\n",
      "test_score  std  0.00489996773907433\n",
      "train_score  mean  0.9390025230452914\n",
      "train_score  std  0.0031482003095237828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnab\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\arnab\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\arnab\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\arnab\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "-----------------------------------\n",
      "fit_time  mean  5.4339102904001875\n",
      "fit_time  std  0.18663581086875983\n",
      "score_time  mean  1.0457820097605388\n",
      "score_time  std  0.023620345736884395\n",
      "test_score  mean  0.7295308419008227\n",
      "test_score  std  0.00047669903814949634\n",
      "train_score  mean  0.9941202459848091\n",
      "train_score  std  0.00038865837156440474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnab\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=True)\n",
      "-----------------------------------\n",
      "fit_time  mean  55.53080463409424\n",
      "fit_time  std  1.5906317322703347\n",
      "score_time  mean  0.9438680013020834\n",
      "score_time  std  0.07045452828366189\n",
      "test_score  mean  0.8051679830572153\n",
      "test_score  std  0.0034147129528237807\n",
      "train_score  mean  0.8340266563999174\n",
      "train_score  std  0.0007063492837913111\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "clfs.append(LogisticRegression())\n",
    "clfs.append(RandomForestClassifier())\n",
    "clfs.append(GradientBoostingClassifier(loss='deviance',warm_start=True))\n",
    "\n",
    "for classifier in clfs:\n",
    "    final_pipeline.set_params(clf = classifier)\n",
    "    scores = cross_validate(final_pipeline, X_train, y_train)\n",
    "    print('---------------------------------')\n",
    "    print(str(classifier))\n",
    "    print('-----------------------------------')\n",
    "    for key, values in scores.items():\n",
    "            print(key,' mean ', values.mean())\n",
    "            print(key,' std ', values.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using GridSearchCV and Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnab\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:  5.2min finished\n",
      "C:\\Users\\arnab\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:436: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8560457581696732\n",
      "Best Paramters:  {'clf__C': 1, 'clf__max_iter': 100, 'clf__penalty': 'l1', 'clf__warm_start': True}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87     12500\n",
      "           1       0.86      0.89      0.88     12500\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_pipeline.set_params(clf = LogisticRegression())\n",
    "parameters_lr = {'clf__C':[1, 0.1,0.01], 'clf__penalty':['l1','l2'], 'clf__warm_start':[True,False], 'clf__max_iter':[100,150,200]}\n",
    "gs_clf_lr = GridSearchCV(final_pipeline, param_grid=parameters_lr, n_jobs=-1,verbose=1)\n",
    "gs_clf_lr = gs_clf_lr.fit(X_train, y_train)\n",
    "print(\"Best Score: \", gs_clf_lr.best_score_)\n",
    "print(\"Best Paramters: \", gs_clf_lr.best_params_)\n",
    "\n",
    "y_pred_lr = gs_clf_lr.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnab\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8028878844846206\n",
      "\n",
      "Best Parameters:  {'clf__criterion': 'entropy', 'clf__n_estimators': 30, 'clf__warm_start': False}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82     12500\n",
      "           1       0.83      0.78      0.80     12500\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     25000\n",
      "   macro avg       0.81      0.81      0.81     25000\n",
      "weighted avg       0.81      0.81      0.81     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_pipeline.set_params(clf = RandomForestClassifier())\n",
    "parameters_rf = {'clf__criterion':['gini','entropy'], 'clf__n_estimators':[10,20,30], 'clf__warm_start':[True,False]}\n",
    "gs_clf_rf = GridSearchCV(final_pipeline, param_grid=parameters_rf, n_jobs=-1,verbose=1)\n",
    "gs_clf_rf = gs_clf_rf.fit(X_train, y_train)\n",
    "print(\"Best Score: \", gs_clf_rf.best_score_)\n",
    "print(\"\\nBest Parameters: \", gs_clf_rf.best_params_)\n",
    "\n",
    "y_pred_rf = gs_clf_rf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnab\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.8088476460941563\n",
      "\n",
      "Best Parameters:  {'clf__learning_rate': 1, 'clf__n_estimators': 30}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81     12500\n",
      "           1       0.81      0.83      0.82     12500\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     25000\n",
      "   macro avg       0.81      0.81      0.81     25000\n",
      "weighted avg       0.81      0.81      0.81     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_pipeline.set_params(clf = GradientBoostingClassifier())\n",
    "parameters_gbc = {'clf__n_estimators':[10,20,30], 'clf__learning_rate':[0.1,0.05,1]}\n",
    "gs_clf_gbc = GridSearchCV(final_pipeline, param_grid=parameters_gbc, n_jobs=-1,verbose=1)\n",
    "gs_clf_gbc = gs_clf_gbc.fit(X_train, y_train)\n",
    "print(\"Best Score: \", gs_clf_gbc.best_score_)\n",
    "print(\"\\nBest Parameters: \", gs_clf_gbc.best_params_)\n",
    "\n",
    "y_pred_gbc = gs_clf_gbc.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_gbc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
